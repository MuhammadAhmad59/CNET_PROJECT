# Traffic Flow Prediction Using STDformer with GCN Enhancement

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.12+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **Team Members**:  
> - Muhammad Ahmad (22I-1929)  
> - Shahzaib Afzal (22I-1956)  
> - Uzair Siddique (22I-6181)

## ğŸ“‹ Project Overview

This repository contains a comprehensive implementation and evaluation of **STDformer-GCN**, an enhanced traffic flow prediction model that integrates Graph Convolutional Networks with the baseline STDformer architecture. Our work builds upon the research paper by Wan et al. (2025) and introduces three major architectural improvements.

### Key Achievements

- âœ… **96.5% MSE reduction** on synthetic data (LSTM+GCN model)
- âœ… **98.6% MSE reduction** on synthetic data (DLinear+GCN model)
- âœ… **7.2% MSE improvement** on PEMS07 dataset (pred_len=24)
- âœ… **Comprehensive evaluation** across 5 datasets and 7 prediction horizons
- âœ… **Detailed ablation study** demonstrating component contributions

### Major Contributions

1. **Learnable Multi-Scale Trend Extraction**: Replaces fixed moving averages with adaptive 1D CNNs (kernel sizes: 3, 5, 7)
2. **Hybrid Seasonal Decomposition**: Combines FFT with dilated temporal convolutions for multi-resolution pattern capture
3. **GCN Spatial Module**: Explicitly models road network topology with 2-layer GCN stack
4. **Extended Training Framework**: 10 epochs with early stopping, enabling proper model convergence

## ğŸ—‚ï¸ Repository Structure

```
CNET_PROJECT/
â”œâ”€â”€ Base Paper/              # Original STDformer paper (Wan et al., 2025)
â”‚   â””â”€â”€ electronics-14-02400-v2.pdf
â”‚
â”œâ”€â”€ Improved Base Paper/     # Our technical report and analysis
â”‚   â””â”€â”€ 22I-1929_22I-1956_22I-6181.pdf
â”‚
â”œâ”€â”€ Baseline/               # Original STDformer implementation
â”‚   â”œâ”€â”€ models/            # Baseline model components
â”‚   â”œâ”€â”€ train_baseline.py  # Training script (1 epoch)
â”‚   â””â”€â”€ README.md          # Baseline documentation
â”‚
â”œâ”€â”€ Enhanced/              # STDformer-GCN enhancements
â”‚   â”œâ”€â”€ models/           # Enhanced components
â”‚   â”‚   â”œâ”€â”€ learnable_trend.py
â”‚   â”‚   â”œâ”€â”€ hybrid_seasonal.py
â”‚   â”‚   â””â”€â”€ gcn_spatial.py
â”‚   â”œâ”€â”€ train_enhanced.py # Training script (10 epochs)
â”‚   â””â”€â”€ README.md         # Enhancement documentation
â”‚
â”œâ”€â”€ data/                 # Datasets and preprocessing
â”‚   â”œâ”€â”€ SYNTH/           # Synthetic traffic data
â”‚   â”œâ”€â”€ PEMS03/          # Real-world traffic flow
â”‚   â”œâ”€â”€ PEMS04/          # Real-world traffic speed
â”‚   â”œâ”€â”€ PEMS07/          # Real-world traffic flow
â”‚   â”œâ”€â”€ PEMS08/          # Real-world traffic speed
â”‚   â””â”€â”€ README.md        # Data documentation
â”‚
â”œâ”€â”€ experiments/         # Training and evaluation scripts
â”‚   â”œâ”€â”€ run_baseline.py
â”‚   â”œâ”€â”€ run_enhanced.py
â”‚   â””â”€â”€ run_ablation.py
â”‚
â”œâ”€â”€ results/            # Experimental results
â”‚   â”œâ”€â”€ tables/        # Performance metrics (CSV/JSON)
â”‚   â”œâ”€â”€ figures/       # Visualizations and plots
â”‚   â””â”€â”€ checkpoints/   # Saved model weights
â”‚
â”œâ”€â”€ requirements.txt   # Python dependencies
â”œâ”€â”€ LICENSE           # MIT License
â””â”€â”€ README.md        # This file
```

## ğŸš€ Quick Start

### Prerequisites

```bash
# Python 3.8 or higher
python --version

# CUDA-capable GPU (recommended)
nvidia-smi
```

### Installation

```bash
# Clone the repository
git clone https://github.com/MuhammadAhmad59/CNET_PROJECT.git
cd CNET_PROJECT

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Dataset Setup

```bash
# Datasets are already included in the repository
# Verify dataset structure
ls data/SYNTH data/PEMS03 data/PEMS04 data/PEMS07 data/PEMS08
```

### Running Experiments

#### Baseline Model (1 Epoch)
```bash
python experiments/run_baseline.py \
    --dataset SYNTH \
    --pred_len 12 \
    --epochs 1 \
    --batch_size 8
```

#### Enhanced Model (10 Epochs)
```bash
python experiments/run_enhanced.py \
    --dataset SYNTH \
    --pred_len 12 \
    --epochs 10 \
    --batch_size 8 \
    --gcn_hidden 64 \
    --dropout 0.2
```

#### Ablation Studies
```bash
# Test without learnable trend
python experiments/run_ablation.py --variant no_learnable_trend

# Test without hybrid seasonal
python experiments/run_ablation.py --variant no_hybrid_seasonal

# Test without GCN
python experiments/run_ablation.py --variant no_gcn

# Full model
python experiments/run_ablation.py --variant full
```

## ğŸ“Š Key Results

### Performance Improvements (SYNTH Dataset, pred_len=12)

| Model | Baseline MSE | Enhanced MSE | Improvement |
|-------|--------------|--------------|-------------|
| Transformer+GCN | 0.964 | 0.713 | 26.0% |
| **LSTM+GCN** | 0.976 | **0.034** | **96.5%** |
| CNN+GCN | 1.000 | 0.701 | 29.9% |
| **DLinear+GCN** | 0.908 | **0.013** | **98.6%** |
| STDformer+GCN | 1.003 | 0.614 | 38.8% |

### Real-World Performance (PEMS07, pred_len=24)

| Model | Baseline MSE | Enhanced MSE | Improvement |
|-------|--------------|--------------|-------------|
| Transformer+GCN | 1.007 | 0.963 | 4.4% |
| **LSTM+GCN** | 1.008 | **0.935** | **7.2%** |
| STDformer+GCN | 1.008 | 0.940 | 6.7% |

### Ablation Study (Average Across All Datasets)

| Configuration | Avg MSE | Avg MAE | Avg RMSE |
|--------------|---------|---------|----------|
| STDformer-GCN (Full) | 1.169 | 0.900 | 1.080 |
| **No Learnable Trend** | **1.145** | **0.892** | **1.068** |
| No Hybrid Seasonal | 1.171 | 0.903 | 1.082 |
| No GCN | 1.186 | 0.909 | 1.088 |
| Baseline STDformer | 1.137 | 0.888 | 1.061 |

**Key Finding**: The "No Learnable Trend" variant achieves the best average performance, suggesting that fixed moving averages may be more stable for the current training setup.

## ğŸ—ï¸ Architecture Overview

### Enhanced STDformer-GCN Pipeline

```
Input Sequence (BÃ—TÃ—N)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Learnable Trend Extraction  â”‚
â”‚ - Multi-scale CNNs (3,5,7)  â”‚
â”‚ - Adaptive fusion            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hybrid Seasonal Decomp      â”‚
â”‚ - FFT (global patterns)     â”‚
â”‚ - Dilated TCN (local bursts)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
  [Trend | Seasonal | Residual]
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Temporal Modeling (Parallel)â”‚
â”‚ - Transformer (trend)       â”‚
â”‚ - Fourier Attn (seasonal)   â”‚
â”‚ - RevIN-MLP (residual)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gating Fusion               â”‚
â”‚ - Learnable gates           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GCN Spatial Module          â”‚
â”‚ - 2-layer GCN stack         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STRA (Spatial-Temporal      â”‚
â”‚       Relation Attention)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    Output Predictions (BÃ—FÃ—N)
```

## ğŸ“ˆ Datasets

| Dataset | Nodes | Length | Frequency | Type |
|---------|-------|--------|-----------|------|
| SYNTH | 10 | 499 | 5 min | Synthetic |
| PEMS03 | 358 | 547 | 5 min | Traffic Flow |
| PEMS04 | 307 | 340 | 5 min | Traffic Speed |
| PEMS07 | 883 | 866 | 5 min | Traffic Flow |
| PEMS08 | 170 | 295 | 5 min | Traffic Speed |

All datasets collected at 5-minute intervals with Z-score normalization. Train/validation/test split: 70%/10%/20%.

## ğŸ”¬ Technical Details

### Hyperparameters

| Parameter | Baseline | Enhanced |
|-----------|----------|----------|
| Model Dimension (d_model) | 32 | 32 |
| GCN Hidden Dimension | N/A | 64 |
| Attention Heads | 4 | 4 |
| Encoder Layers | 2 | 2 |
| Dropout | 0.0 | 0.2 |
| Batch Size | 8 | 8 |
| Learning Rate | 0.001 | 0.001 |
| Epochs | 1 | 10 |
| Early Stopping Patience | N/A | 5 |

### Training Environment

- **Hardware**: NVIDIA GeForce RTX 4090 24GB
- **Operating System**: Windows 11
- **Framework**: PyTorch 1.12+
- **Optimizer**: Adam (Î²â‚=0.9, Î²â‚‚=0.999)
- **Loss Function**: Mean Squared Error (MSE)

## ğŸ“š Documentation

- **[Base Paper](Base%20Paper/electronics-14-02400-v2.pdf)**: Original STDformer research
- **[Technical Report](Improved%20Base%20Paper/22I-1929_22I-1956_22I-6181.pdf)**: Complete implementation analysis
- **[Baseline README](Baseline/README.md)**: Original implementation details
- **[Enhanced README](Enhanced/README.md)**: Enhancement documentation
- **[Data README](data/README.md)**: Dataset information

## ğŸ¤ Team Contributions

| Member | Responsibilities |
|--------|-----------------|
| **Muhammad Ahmad** (22I-1929) | GCN Integration, Adjacency Matrix Construction, Ablation Studies |
| **Shahzaib Afzal** (22I-1956) | Learnable Trend Extraction, Hybrid Seasonal Decomposition, Training Framework |
| **Uzair Siddique** (22I-6181) | Experimental Evaluation, Performance Analysis, Data Pipeline, Visualization |

All team members contributed to architecture design, code review, documentation, and problem-solving.

## ğŸ“– Citations

### Reference Paper

```bibtex
@article{wan2025stdformer,
  title={Spatial-Temporal Traffic Flow Prediction Through Residual-Trend Decomposition with Transformer Architecture},
  author={Wan, Hongyang and Xu, Haijiao and Xie, Liang},
  journal={Electronics},
  volume={14},
  number={12},
  pages={2400},
  year={2025},
  publisher={MDPI}
}
```

### Our Work

```bibtex
@techreport{ahmad2025stdformergcn,
  title={Traffic Flow Prediction Using STDformer with GCN Enhancement: Implementation and Performance Analysis},
  author={Ahmad, Muhammad and Afzal, Shahzaib and Siddique, Uzair},
  year={2025},
  institution={CS3001 - Computer Networks, Fall 2025},
  type={Course Project Report}
}
```

## âš ï¸ Known Limitations

1. **Long-Horizon Predictions**: Both baseline and enhanced models fail on 720-step predictions
2. **Small Datasets**: Degraded performance on PEMS04 and PEMS08 (limited training samples)
3. **Dataset-Specific Behavior**: PEMS03 shows mixed results requiring further investigation
4. **Computational Cost**: 33% memory increase, 10-15% longer training time per epoch

## ğŸ”® Future Work

- [ ] Hierarchical multi-stage forecasting for long horizons (720+ steps)
- [ ] Transfer learning from large datasets to small datasets
- [ ] Dataset-specific hyperparameter tuning and adaptive learning rates
- [ ] Physical road network integration with actual connectivity data
- [ ] Real-time adaptation and online learning mechanisms
- [ ] Uncertainty quantification with confidence intervals
- [ ] Model compression for deployment efficiency

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Original STDformer authors (Wan et al., 2025) for the foundational architecture
- PEMS database for providing publicly accessible traffic data
- PyTorch and open-source community for development tools
- Course instructor and teaching assistants for guidance and support

## ğŸ“ Contact

For questions, collaborations, or feedback:

- Muhammad Ahmad: [ahmad22i1929@gmail.com]
- Shahzaib Afzal: [shahzaib22i1956@gmail.com]
- Uzair Siddique: [uzair22i6181@gmail.com]

---

**Academic Context**: This work was developed as part of CS3001 - Computer Networks (Fall 2025) and represents a research-based implementation project combining computer networks principles with advanced machine learning techniques for traffic flow prediction.
